{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74ba9c53",
   "metadata": {},
   "source": [
    "## Objective: Implement back propagation from scratch with derivaties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50cd3ff",
   "metadata": {},
   "source": [
    "### Single layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e6a10c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b795690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(predictions,actual):\n",
    "    return np.mean((predictions-actual)**2)\n",
    "\n",
    "def forward_pass(x,w,b,actual):\n",
    "    z = np.dot(x,w) + b\n",
    "    predicted = np.maximum(0,z) # relu activation\n",
    "    loss = mse_loss(predicted,actual)\n",
    "\n",
    "    print('Ouput after 1 layer:',z)\n",
    "    print('Prediction after 1 layer:',predicted)\n",
    "    print('Loss after 1 layer',loss)\n",
    "\n",
    "    return z , predicted , loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d2d732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(x,w,b,actual):\n",
    "    z , predicted , loss = forward_pass(x,w,b,actual)\n",
    "\n",
    "    dL_dpred = 2 * (predicted - actual) / len(z)\n",
    "    dpred_dz = np.where(z > 0 , 1 ,0)\n",
    "\n",
    "    print(f\"dL_dpred shape: {dL_dpred.shape}\")  # (3,)\n",
    "    print(f\"dpred_dz shape: {dpred_dz.shape}\")  # (3,)\n",
    "    print(f\"dL_dpred: {dL_dpred}\")\n",
    "    print(f\"dpred_dz: {dpred_dz}\")\n",
    "\n",
    "    #chain rule\n",
    "    print((dL_dpred * dpred_dz)[:, np.newaxis]*x)\n",
    "    dL_dw = np.mean((dL_dpred * dpred_dz)[:, np.newaxis] * x, axis=0)\n",
    "    dL_db = np.mean(dL_dpred * dpred_dz)\n",
    "\n",
    "    return dL_dw , dL_db , loss , predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a34cebc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouput after 1 layer: [1.5 1.4 0.5]\n",
      "Prediction after 1 layer: [1.5 1.4 0.5]\n",
      "Loss after 1 layer 0.82\n",
      "dL_dpred shape: (3,)\n",
      "dpred_dz shape: (3,)\n",
      "dL_dpred: [0.33333333 0.93333333 0.33333333]\n",
      "dpred_dz: [1 1 1]\n",
      "[[ 0.33333333  0.66666667]\n",
      " [ 1.86666667  0.93333333]\n",
      " [-0.33333333 -0.66666667]]\n",
      "\n",
      " ####################################################################################################\n",
      "Loss with respect to weight: [0.62222222 0.31111111]\n",
      "Loss with respect to bias: 0.5333333333333333\n",
      "New Weights: [0.10622222 0.20311111]\n",
      "New bias: 1.0053333333333334\n"
     ]
    }
   ],
   "source": [
    "x = [[1.0,2.0],\n",
    "     [2.0,1.0],\n",
    "     [-1.0,-2.0]] # 3 x 2\n",
    "\n",
    "w = [0.1,0.2] # 1 x 2\n",
    "\n",
    "b = 1\n",
    "actual = [1,0,0]\n",
    "learning_rate = 0.01\n",
    "\n",
    "dL_dw , dL_db , loss , predicted = backward_pass(x,w,b,actual)\n",
    "\n",
    "nw = w - learning_rate * -dL_dw\n",
    "nb = b - learning_rate * -dL_db\n",
    "\n",
    "print(\"\\n\",\"#\"*100)\n",
    "print('Loss with respect to weight:',dL_dw)\n",
    "print('Loss with respect to bias:',dL_db)\n",
    "print('New Weights:',nw)\n",
    "print('New bias:',nb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
